{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigmf_pytorch_dataset import SigMFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SigMFDataset( root=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.visualize import IQVisualizer, SpectrogramVisualizer, two_channel_to_complex\n",
    "from torchsig.utils.dataset import SignalDataset\n",
    "from torchsig.datasets.sig53 import Sig53\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = dataset[0]\n",
    "print(\"Data shape: {}\".format(data.shape))\n",
    "print(\"Label shape: {}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "labels = []\n",
    "for _, label in dataset:\n",
    "    labels.append(label)\n",
    "\n",
    "print(\"Unique labels: {}\".format(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "visualizer = IQVisualizer(\n",
    "    data_loader=data_loader\n",
    ")\n",
    "\n",
    "for figure in iter(visualizer):\n",
    "    figure.set_size_inches(16, 16)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SigMF based Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.models.iq_models.efficientnet.efficientnet import efficientnet_b4\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchsig.utils.cm_plotter import plot_confusion_matrix\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "from torchsig.datasets.sig53 import Sig53\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torchsig.transforms as ST\n",
    "import numpy as np\n",
    "import torchsig\n",
    "import torch\n",
    "import os\n",
    "from sigmf_db_dataset import SigMFDB\n",
    "from sigmf_pytorch_dataset import SigMFDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SigMF File dataset\n",
    "and generate the class list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ST.Compose([\n",
    "    ST.RandomPhaseShift(phase_offset=(-1, 1)),\n",
    "    ST.Normalize(norm=np.inf),\n",
    "    ST.ComplexTo2D(),\n",
    "])\n",
    "class_list = ['signal', 'mini2_video']\n",
    "dataset = SigMFDataset( root=\".\",\n",
    "                       transform=transform,\n",
    "                       class_list=class_list,\n",
    ")\n",
    "labels = []\n",
    "for _, label in dataset:\n",
    "    labels.append(label)\n",
    "#class_list=np.unique(labels).tolist()\n",
    "print(\"Unique labels: {}\".format(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SigMF DB Data Loaders\n",
    "The number of workers needs to be set to 0 when there is not a GPU. Otherwise the dataloader tries to pickle the environment variables: https://github.com/acids-ircam/RAVE/issues/10#issuecomment-1002708207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify Sig53 Options\n",
    "\n",
    "root = \"sigmf/\"\n",
    "train = False\n",
    "impaired = False\n",
    "class_list = ['signal', 'mini2_video']\n",
    "print(\"Class List: {}\".format(class_list))\n",
    "transform = ST.Compose([\n",
    "    ST.RandomPhaseShift(phase_offset=(-1, 1)),\n",
    "    ST.Normalize(norm=np.inf),\n",
    "    ST.ComplexTo2D(),\n",
    "])\n",
    "target_transform = ST.DescToClassIndex(class_list=class_list)\n",
    "\n",
    "sig53_clean_train = SigMFDB(\n",
    "    root=root, \n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    "    use_signal_data=True,\n",
    ")\n",
    "\n",
    "# Retrieve a sample and print out information to verify\n",
    "print(len(sig53_clean_train))\n",
    "idx = np.random.randint(len(sig53_clean_train))\n",
    "data, label = sig53_clean_train[idx]\n",
    "print(\"Dataset length: {}\".format(len(sig53_clean_train)))\n",
    "print(\"Data shape: {}\".format(data.shape))\n",
    "print(\"Data Object: {}\".format(data))\n",
    "print(\"Label Index: {}\".format(label))\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    sig53_clean_train ,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    sig53_clean_train ,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SigMF File Dataloaders\n",
    "This is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=dataset, #sig53_clean_train ,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=dataset, #sig53_clean_train ,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b4(\n",
    "    pretrained=True,\n",
    "    path=\"efficientnet_b4.pt\",\n",
    ")\n",
    "\n",
    "device = torch.device('cpu') #('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleNetwork(LightningModule):\n",
    "    def __init__(self, model, data_loader, val_data_loader):\n",
    "        super(ExampleNetwork, self).__init__()\n",
    "        self.mdl = model\n",
    "        self.data_loader = data_loader\n",
    "        self.val_data_loader = val_data_loader\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = data_loader.batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mdl(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.data_loader\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        loss = F.cross_entropy(self(x.float()), y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_data_loader\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        val_loss = F.cross_entropy(self(x.float()), y)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        return {\"val_loss\": val_loss}\n",
    "\n",
    "example_model = ExampleNetwork(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup checkpoint callbacks\n",
    "checkpoint_filename = \"{}/checkpoints/checkpoint\".format(os.getcwd())\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=checkpoint_filename,\n",
    "    save_top_k=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "print(\"Doing stuff\")\n",
    "# Create and fit trainer\n",
    "epochs = 25\n",
    "trainer = Trainer(\n",
    "    max_epochs=epochs, callbacks=checkpoint_callback, accelerator=\"cpu\", devices=1\n",
    ")\n",
    "trainer.fit(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfml-dev-Rt5ZGM-V-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
