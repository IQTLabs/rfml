{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.visualize import (\n",
    "    MaskClassVisualizer,\n",
    "    mask_class_to_outline,\n",
    "    complex_spectrogram_to_magnitude,\n",
    ")\n",
    "from torchsig.transforms.target_transforms import DescToMaskClass, DescToListTuple\n",
    "from torchsig.transforms import Spectrogram, Normalize\n",
    "from torchsig.utils.writer import DatasetCreator, DatasetLoader\n",
    "from torchsig.datasets.wideband_sig53 import WidebandSig53\n",
    "from torchsig.datasets.wideband import WidebandModulationsDataset\n",
    "from torchsig.transforms.transforms import Compose\n",
    "from torchsig.datasets import conf\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchsig.utils.types import SignalCapture, SignalDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SIGMF_DTYPE_MAP: Dict[str, np.dtype] = {\n",
    "    \"cf64_le\": np.dtype(\"<f8\"),\n",
    "    \"cf64_be\": np.dtype(\">f8\"),\n",
    "    \"cf32_le\": np.dtype(\"<f4\"),\n",
    "    \"cf32_be\": np.dtype(\">f4\"),\n",
    "    \"ci32_le\": np.dtype(\"<i4\"),\n",
    "    \"ci32_be\": np.dtype(\">i4\"),\n",
    "    \"ci16_le\": np.dtype(\"<i2\"),\n",
    "    \"ci16_be\": np.dtype(\">i2\"),\n",
    "    \"ci8_le\": np.dtype(\"<i1\"),\n",
    "    \"ci8_be\": np.dtype(\">i1\"),\n",
    "    \"cu32_le\": np.dtype(\"<u4\"),\n",
    "    \"cu32_be\": np.dtype(\">u4\"),\n",
    "    \"cu16_le\": np.dtype(\"<u2\"),\n",
    "    \"cu16_be\": np.dtype(\">u2\"),\n",
    "    \"cu8_le\": np.dtype(\"<u1\"),\n",
    "    \"cu8_be\": np.dtype(\">u1\"),\n",
    "    \"rf64_le\": np.dtype(\"<f8\"),\n",
    "    \"rf64_be\": np.dtype(\">f8\"),\n",
    "    \"rf32_le\": np.dtype(\"<f4\"),\n",
    "    \"rf32_be\": np.dtype(\">f4\"),\n",
    "    \"ri32_le\": np.dtype(\"<i4\"),\n",
    "    \"ri32_be\": np.dtype(\">i4\"),\n",
    "    \"ri16_le\": np.dtype(\"<i2\"),\n",
    "    \"ri16_be\": np.dtype(\">i2\"),\n",
    "    \"ri8_le\": np.dtype(\"<i1\"),\n",
    "    \"ri8_be\": np.dtype(\">i1\"),\n",
    "    \"ru32_le\": np.dtype(\"<u4\"),\n",
    "    \"ru32_be\": np.dtype(\">u4\"),\n",
    "    \"ru16_le\": np.dtype(\"<u2\"),\n",
    "    \"ru16_be\": np.dtype(\">u2\"),\n",
    "    \"ru8_le\": np.dtype(\"<u1\"),\n",
    "    \"ru8_be\": np.dtype(\">u1\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer_from_folders_sigmf(root: str) -> List[Tuple[Any, SignalCapture]]:\n",
    "    \"\"\"An indexer where classes are delineated by folders\n",
    "\n",
    "    Notes:\n",
    "        Assumes data is stored as follows:\n",
    "            root/class_x/xxx.sigmf-data\n",
    "            root/class_x/xxx.sigmf-meta\n",
    "\n",
    "            root/class_y/yxx.sigmf-data\n",
    "            root/class_y/yxx.sigmf-meta\n",
    "\n",
    "    Args:\n",
    "        root:\n",
    "\n",
    "    Returns:\n",
    "        index: tuple of target, meta-data pairs\n",
    "\n",
    "    \"\"\"\n",
    "    # go through directories and find files\n",
    "    non_empty_dirs = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "    non_empty_dirs.append(root)\n",
    "    #non_empty_dirs = [d for d in non_empty_dirs if os.listdir(os.path.join(root, d))]\n",
    "    #print(non_empty_dirs)\n",
    "    # Identify all files associated with each class\n",
    "    index = []\n",
    "    for dir_idx, dir_name in enumerate(non_empty_dirs):\n",
    "        class_dir = os.path.join(root, dir_name)\n",
    "\n",
    "        # Find files with sigmf-data at the end and make a list\n",
    "        proper_sigmf_files = list(\n",
    "            filter(\n",
    "                lambda x: x.split(\".\")[-1] in {\"sigmf-data\"}\n",
    "                and os.path.isfile(os.path.join(class_dir, x)),\n",
    "                os.listdir(os.path.join(root, dir_name)),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Go through each file and create and index\n",
    "        for f in proper_sigmf_files:\n",
    "            index = index + _parse_sigmf_anotations(os.path.join(class_dir, f))\n",
    "\n",
    "    return index\n",
    "\n",
    "def _parse_sigmf_anotations(absolute_file_path: str) -> List[SignalCapture]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        absolute_file_path: absolute file path of sigmf-meta file for which to create Captures\n",
    "\n",
    "    Returns:\n",
    "        signal_files:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    meta_file_name = \"{}{}\".format(absolute_file_path.split(\"sigmf-data\")[0], \"sigmf-meta\")\n",
    "    meta = json.load(open(meta_file_name, \"r\"))\n",
    "    item_type = SIGMF_DTYPE_MAP[meta[\"global\"][\"core:datatype\"]]\n",
    "    sample_size = item_type.itemsize * (2 if \"c\" in meta[\"global\"][\"core:datatype\"] else 1)\n",
    "    total_num_samples = os.path.getsize(absolute_file_path) // sample_size\n",
    "\n",
    "    # It's quite common for there to be only a single \"capture\" in sigMF\n",
    "    index = []\n",
    "    if len(meta[\"captures\"]) == 1:\n",
    "        for annotation in meta[\"annotations\"]:\n",
    "            sample_start = annotation[\"core:sample_start\"]\n",
    "            sample_count = annotation[\"core:sample_count\"]\n",
    "            signal_description = SignalDescription(\n",
    "                sample_rate=meta[\"global\"][\"core:sample_rate\"],\n",
    "            )\n",
    "            signal_description.upper_frequency = annotation[\"core:freq_upper_edge\"]\n",
    "            signal_description.lower_frequency = annotation[\"core:freq_lower_edge\"]    \n",
    "            label = annotation[\"core:label\"]\n",
    "            comment = annotation[\"core:comment\"]\n",
    "\n",
    "\n",
    "        \n",
    "            signal =  SignalCapture(\n",
    "                    absolute_path=absolute_file_path,\n",
    "                    num_bytes=sample_size * sample_count,\n",
    "                    byte_offset=sample_size * sample_start,\n",
    "                    item_type=item_type,\n",
    "                    is_complex=True if \"c\" in meta[\"global\"][\"core:datatype\"] else False,\n",
    "                    signal_description=signal_description,\n",
    "                )\n",
    "            index.append((label, signal))\n",
    "            #print(f\"Signal {label}  {signal.num_bytes} {signal.byte_offset} {signal.item_type} {signal.is_complex} \")\n",
    "    else:\n",
    "        print(\"Not Clear how we should handle the annotations when there is more than one capture\")\n",
    "    # If there's more than one, we construct a list of captures\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.types import SignalCapture, SignalData\n",
    "import torchsig.utils.reader as reader\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "class SignalDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"An abstract dataset class to be sub-classed by SignalDatasets\n",
    "\n",
    "    Args:\n",
    "        transform:\n",
    "            Transforms to be applied to SignalData Objects\n",
    "\n",
    "        target_transform:\n",
    "            Transforms to be applied to dataset targets\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        seed: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        super(SignalDataset, self).__init__()\n",
    "        self.random_generator = np.random.RandomState(seed)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        index: int,\n",
    "    ) -> Tuple[Union[SignalData, np.ndarray], Any]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SigMFDataset(SignalDataset):\n",
    "    \"\"\"SignalFileDataset is meant to make a mappable (index-able) dataset from\n",
    "    a set of files\n",
    "\n",
    "    Args:\n",
    "        root:\n",
    "            Root file path to search recursively for files\n",
    "\n",
    "        indexer:\n",
    "            Using root, constructs an index of data/meta-data\n",
    "\n",
    "        reader:\n",
    "            Given a file path, produces an SignalData object\n",
    "\n",
    "        index_filter:\n",
    "            Given an index, remove certain elements\n",
    "\n",
    "        *\\\\*kwargs:**\n",
    "            Keyword arguments\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        indexer: Callable[[str], List[Tuple[Any, SignalCapture]]],\n",
    "        reader: Callable[[SignalCapture], SignalData],\n",
    "        index_filter: Optional[Callable[[Tuple[Any, SignalCapture]], bool]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(SigMFDataset, self).__init__(**kwargs)\n",
    "        self.reader = reader\n",
    "        self.index = indexer(root)\n",
    "        if index_filter:\n",
    "            self.index = list(filter(index_filter, self.index))\n",
    "\n",
    "    def __getitem__(self, item: int) -> Tuple[np.ndarray, Any]:  # type: ignore\n",
    "        target = self.index[item][0]\n",
    "        signal_data = self.reader(self.index[item][1])\n",
    "\n",
    "        if self.transform:\n",
    "            signal_data = self.transform(signal_data)\n",
    "\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return signal_data.iq_data, target  # type: ignore\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.index)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SigMFDataset( root=\".\", indexer=indexer_from_folders_sigmf, reader=reader.reader_from_sigmf, index_filter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0. +0.j,  -16.-28.j,  -14. +7.j, ..., -113.-62.j, -131.-88.j,\n",
      "       -127.-53.j]), 'signal')\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfml-dev-Rt5ZGM-V-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
